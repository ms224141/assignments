{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLYE/6qq/CklgjEL809gTO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ms224141/assignments/blob/main/regression_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "jo16tCbtXUj8",
        "outputId": "efa54049-3eeb-4558-c6f0-90f55052d388"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSimple Linear Regression is a statistical method used to model the relationship between a dependent variable (Y) and a single independent variable (X) using a linear equation:\\nY = mX + c\\nwhere:\\n- m is the slope (coefficient)\\n- c is the intercept\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "\n",
        "# What is Simple Linear Regression?\n",
        "\"\"\"\n",
        "Simple Linear Regression is a statistical method used to model the relationship between a dependent variable (Y) and a single independent variable (X) using a linear equation:\n",
        "Y = mX + c\n",
        "where:\n",
        "- m is the slope (coefficient)\n",
        "- c is the intercept\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# What are the key assumptions of Simple Linear Regression?\n",
        "\"\"\"\n",
        "1. Linearity: The relationship between X and Y is linear.\n",
        "2. Independence: Observations are independent of each other.\n",
        "3. Homoscedasticity: Constant variance of residuals.\n",
        "4. Normality: Residuals should be normally distributed.\n",
        "5. No multicollinearity (only one independent variable).\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "PpcMG2CbX6aq",
        "outputId": "22df0871-994b-470e-d056-69e0748721d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. Linearity: The relationship between X and Y is linear.\\n2. Independence: Observations are independent of each other.\\n3. Homoscedasticity: Constant variance of residuals.\\n4. Normality: Residuals should be normally distributed.\\n5. No multicollinearity (only one independent variable).\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What does the coefficient m represent in the equation Y=mX+c?\n",
        "\"\"\"\n",
        "The coefficient m represents the slope of the regression line, indicating the rate of change in Y for a one-unit change in X.\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "HNjvhBUeYBUs",
        "outputId": "99bd2ee5-a63f-49b1-a47d-49e179b2aadc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe coefficient m represents the slope of the regression line, indicating the rate of change in Y for a one-unit change in X.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What does the intercept c represent in the equation Y=mX+c?\n",
        "\"\"\"\n",
        "The intercept c represents the expected value of Y when X is zero.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "i4BU1_AxYFjV",
        "outputId": "a02f1f23-367f-423c-fb7c-30cbe2b9a90e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe intercept c represents the expected value of Y when X is zero.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# How do we calculate the slope m in Simple Linear Regression?\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def calculate_slope(X, Y):\n",
        "    n = len(X)\n",
        "    numerator = n * np.sum(X * Y) - np.sum(X) * np.sum(Y)\n",
        "    denominator = n * np.sum(X**2) - (np.sum(X))**2\n",
        "    return numerator / denominator\n"
      ],
      "metadata": {
        "id": "UZXEGm_YYQl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\"\"\"\n",
        "The least squares method minimizes the sum of squared residuals (differences between actual and predicted values) to find the best-fitting regression line.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_NTqvsyCYVNK",
        "outputId": "a580c500-50c1-4b9f-e0da-1a4be749c7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe least squares method minimizes the sum of squared residuals (differences between actual and predicted values) to find the best-fitting regression line.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
        "\"\"\"\n",
        "R² measures how well the regression model explains the variance in the dependent variable. It ranges from 0 to 1:\n",
        "- R² = 1: Perfect fit\n",
        "- R² = 0: No predictive power\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3GqD86_JYYmz",
        "outputId": "7b8dbda9-d8c1-46b1-afd1-ef7b1604ffd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nR² measures how well the regression model explains the variance in the dependent variable. It ranges from 0 to 1:\\n- R² = 1: Perfect fit\\n- R² = 0: No predictive power\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Multiple Linear Regression\n",
        "\n",
        "# What is Multiple Linear Regression?\n",
        "\"\"\"\n",
        "Multiple Linear Regression is an extension of Simple Linear Regression where two or more independent variables are used to predict a dependent variable:\n",
        "Y = b0 + b1X1 + b2X2 + ... + bnXn\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "XZ2QNJLYYXbh",
        "outputId": "9e12df4d-7cfe-4b17-d97a-1e979d883481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nMultiple Linear Regression is an extension of Simple Linear Regression where two or more independent variables are used to predict a dependent variable:\\nY = b0 + b1X1 + b2X2 + ... + bnXn\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# What is the main difference between Simple and Multiple Linear Regression?\n",
        "\"\"\"\n",
        "Simple Linear Regression uses one independent variable, while Multiple Linear Regression uses multiple independent variables.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "6QlgZ0jcYZEm",
        "outputId": "184ecc25-3892-400d-c8f3-61b57fd951a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSimple Linear Regression uses one independent variable, while Multiple Linear Regression uses multiple independent variables.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# What are the key assumptions of Multiple Linear Regression?\n",
        "\"\"\"\n",
        "1. Linearity\n",
        "2. Independence of errors\n",
        "3. Homoscedasticity\n",
        "4. Normality of residuals\n",
        "5. No multicollinearity among independent variables\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "9zJL9cw4YazX",
        "outputId": "7dd524cf-7d2b-4039-920b-5ef62857aa37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. Linearity\\n2. Independence of errors\\n3. Homoscedasticity\\n4. Normality of residuals\\n5. No multicollinearity among independent variables\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "\"\"\"\n",
        "Heteroscedasticity occurs when the variance of residuals is not constant. It can affect the reliability of coefficient estimates and p-values.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "IfgQI4qbYbNu",
        "outputId": "f8ad1784-bc68-4b26-bd1b-bea001bd6bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nHeteroscedasticity occurs when the variance of residuals is not constant. It can affect the reliability of coefficient estimates and p-values.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\"\"\"\n",
        "1. Remove highly correlated independent variables.\n",
        "2. Use Principal Component Analysis (PCA).\n",
        "3. Apply Ridge or Lasso Regression.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "113vY8vUYbhc",
        "outputId": "2cf6edd2-7bd4-4062-f3ab-407e48e1c5c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. Remove highly correlated independent variables.\\n2. Use Principal Component Analysis (PCA).\\n3. Apply Ridge or Lasso Regression.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\"\"\"\n",
        "1. One-hot encoding\n",
        "2. Label encoding\n",
        "3. Dummy variable encoding\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GFZMl5MLYb8T",
        "outputId": "dc4eb92a-2cda-49d7-c980-166e4bbae96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. One-hot encoding\\n2. Label encoding\\n3. Dummy variable encoding\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# What is the role of interaction terms in Multiple Linear Regression?\n",
        "\"\"\"\n",
        "Interaction terms capture the combined effect of two independent variables on the dependent variable.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ZYS5L2ynYcLQ",
        "outputId": "245032be-20c7-4f47-bad2-34344495a643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nInteraction terms capture the combined effect of two independent variables on the dependent variable.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\"\"\"\n",
        "In Simple Linear Regression, the intercept represents Y when X=0. In Multiple Linear Regression, it represents Y when all independent variables are zero.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "HKFNEuXnYcXK",
        "outputId": "70d26a89-1ead-4808-8089-7bf2c30b1019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIn Simple Linear Regression, the intercept represents Y when X=0. In Multiple Linear Regression, it represents Y when all independent variables are zero.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\"\"\"\n",
        "The slope indicates how much Y changes for a one-unit increase in X. A positive slope means Y increases with X, while a negative slope means Y decreases.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "9zGdyXtSYciU",
        "outputId": "ba7da419-17fc-478e-f7c7-05fafa50e0a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe slope indicates how much Y changes for a one-unit increase in X. A positive slope means Y increases with X, while a negative slope means Y decreases.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# How does the intercept in a regression model provide context for the relationship between variables?\n",
        "\"\"\"\n",
        "The intercept provides a baseline value of the dependent variable when all independent variables are zero.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QtJj_Xi9Ycs_",
        "outputId": "3c94e7e3-27bc-43ab-d2e8-9b3060e35615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe intercept provides a baseline value of the dependent variable when all independent variables are zero.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# What are the limitations of using R² as a sole measure of model performance?\n",
        "\"\"\"\n",
        "1. R² does not indicate if the model is correct.\n",
        "2. A high R² can result from overfitting.\n",
        "3. It does not measure predictive accuracy.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Q4HNgQoLYc3e",
        "outputId": "a76546fc-6d2d-42be-fcd3-e105b92d50fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. R² does not indicate if the model is correct.\\n2. A high R² can result from overfitting.\\n3. It does not measure predictive accuracy.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# How would you interpret a large standard error for a regression coefficient?\n",
        "\"\"\"\n",
        "A large standard error suggests that the coefficient estimate is uncertain and may not be statistically significant.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-z20boPsYdHV",
        "outputId": "52110f84-18fa-47db-f946-382c1e93fa22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nA large standard error suggests that the coefficient estimate is uncertain and may not be statistically significant.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\"\"\"\n",
        "Heteroscedasticity can be identified by plotting residuals against fitted values. If the spread increases, heteroscedasticity is present.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "eMESxOxSYdTd",
        "outputId": "61bd5ed9-cda0-4cd5-ae36-02349794eccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nHeteroscedasticity can be identified by plotting residuals against fitted values. If the spread increases, heteroscedasticity is present.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
        "\"\"\"\n",
        "This indicates overfitting, where unnecessary independent variables inflate R² without improving predictive power.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Gs3gQptCZOKu",
        "outputId": "c6852eea-1750-47bc-b455-95b164deaada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThis indicates overfitting, where unnecessary independent variables inflate R² without improving predictive power.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Why is it important to scale variables in Multiple Linear Regression?\n",
        "\"\"\"\n",
        "Scaling ensures that all variables contribute equally to the model and prevents dominance by variables with larger magnitudes.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "EodPZZgHZOHS",
        "outputId": "4f292ac0-6979-46a2-f92d-3d085395dedc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nScaling ensures that all variables contribute equally to the model and prevents dominance by variables with larger magnitudes.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Polynomial Regression\n",
        "\n",
        "# What is polynomial regression?\n",
        "\"\"\"\n",
        "Polynomial regression is a type of regression where the relationship between independent and dependent variables is modeled as an nth-degree polynomial.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-LbdnqzaZOEf",
        "outputId": "6b118b68-5a86-407f-e398-d208e1dddcc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPolynomial regression is a type of regression where the relationship between independent and dependent variables is modeled as an nth-degree polynomial.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# How does polynomial regression differ from linear regression?\n",
        "\"\"\"\n",
        "Polynomial regression allows for curved relationships between variables, unlike linear regression, which assumes a straight-line relationship.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "AkZmSL-IZOBY",
        "outputId": "41fccad2-f1fb-4470-ee47-a88dbebfafe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPolynomial regression allows for curved relationships between variables, unlike linear regression, which assumes a straight-line relationship.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# When is polynomial regression used?\n",
        "\"\"\"\n",
        "Polynomial regression is used when the relationship between variables is non-linear.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xeYDLnKzZN-v",
        "outputId": "e6887677-270a-4a3f-e174-da725725dd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPolynomial regression is used when the relationship between variables is non-linear.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# What is the general equation for polynomial regression?\n",
        "\"\"\"\n",
        "Y = b0 + b1X + b2X^2 + ... + bnX^n\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KI06S4BHZN7y",
        "outputId": "fe62b90d-0745-4ab5-e107-b7d1cf0a180e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nY = b0 + b1X + b2X^2 + ... + bnX^n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Can polynomial regression be applied to multiple variables?\n",
        "\"\"\"\n",
        "Yes, polynomial regression can be extended to multiple variables by including polynomial terms of each variable.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Aw9OHFi1ZN4c",
        "outputId": "3ec62a9a-805d-4028-cf89-cae649c8ef1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nYes, polynomial regression can be extended to multiple variables by including polynomial terms of each variable.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# What are the limitations of polynomial regression?\n",
        "\"\"\"\n",
        "1. Overfitting with high-degree polynomials.\n",
        "2. Extrapolation can be unreliable.\n",
        "3. Computational complexity increases with degree.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "klT1-GkPZN1K",
        "outputId": "1cb905b4-cdcc-421d-feea-4567f19e66e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. Overfitting with high-degree polynomials.\\n2. Extrapolation can be unreliable.\\n3. Computational complexity increases with degree.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# How is polynomial regression implemented in Python?\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def polynomial_regression(X, Y, degree):\n",
        "    poly = PolynomialFeatures(degree=degree)\n",
        "    X_poly = poly.fit_transform(X.reshape(-1, 1))\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_poly, Y)\n",
        "\n"
      ],
      "metadata": {
        "id": "OfH_RpInZNrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OtkVO3WfZNe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SELSrSFXZNPQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}